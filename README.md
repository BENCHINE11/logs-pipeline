# ğŸ“˜ Logs Pipeline â€“ Big Data / Data Engineering
## ğŸ“Œ Description du projet

Ce projet met en Å“uvre un pipeline Big Data complet pour le traitement et lâ€™analyse de logs applicatifs en temps rÃ©el et en batch.

Il simule un cas rÃ©el de Data Engineering, depuis la gÃ©nÃ©ration des logs jusquâ€™Ã  la production dâ€™indicateurs analytiques exploitables, en sâ€™appuyant sur les technologies suivantes :

- Apache Kafka : ingestion des donnÃ©es en temps rÃ©el
- Apache Spark : traitement streaming et batch
- HDFS : stockage distribuÃ© (Data Lake)
- Docker & Docker Compose : orchestration de lâ€™infrastructure

## ğŸ—ï¸ Architecture globale
```bash
Python Producer
â†“
Kafka (logs_raw)
â†“
Spark Structured Streaming
â†“
HDFS (curated)
â†“
Spark Batch Analytics
â†“
HDFS (analytics)
```

## âœ… PrÃ©requis

Avant de lancer le projet, assure-toi dâ€™avoir les Ã©lÃ©ments suivants installÃ©s :

### ğŸ”§ Outils systÃ¨me

- Docker â‰¥ 24.x
- Docker Compose â‰¥ 2.x
- Git

### ğŸ Python

- Python 3.10+
- Pip installÃ©

### ğŸ§  Connaissances recommandÃ©es

- Bases de Kafka, Spark et Hadoop
- Utilisation du terminal (PowerShell / Bash)

## ğŸ“‚ Structure du projet
```bash
logs-pipeline/
â”‚
â”œâ”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ producer/
â”‚   â””â”€â”€ produce_logs.py
â”‚
â”œâ”€â”€ spark-streaming/
â”‚   â””â”€â”€ src/main/scala/com/myapp/logs/StreamingJob.scala
â”‚
â”œâ”€â”€ spark-batch/
â”‚   â””â”€â”€ src/main/scala/com/myapp/logs/BatchAnalytics.scala
â”‚
â”œâ”€â”€ images/                # Screenshots pour le rapport
â”‚
â””â”€â”€ README.md
```

## ğŸš€ Lancement du pipeline (pas Ã  pas)
### 1ï¸âƒ£ Cloner le projet
```git
git clone https://github.com/BENCHINE11/logs-pipeline.git
cd logs-pipeline
```

### 2ï¸âƒ£ Lancer lâ€™infrastructure Docker
```bash 
docker compose up -d
```

VÃ©rifier que tous les services sont actifs :
```bash
docker ps
```


Tu dois voir au minimum :

- kafka
- zookeeper
- spark
- namenode
- datanode

### 3ï¸âƒ£ CrÃ©er le topic Kafka
```bash
docker exec -it kafka kafka-topics \
--bootstrap-server kafka:9092 \
--create \
--topic logs_raw \
--partitions 3 \
--replication-factor 1
```

Lister les topics :
```bash
docker exec -it kafka kafka-topics \
--bootstrap-server kafka:9092 \
--list
```

### 4ï¸âƒ£ Installer les dÃ©pendances Python (host)
```bash 
pip install kafka-python
```

### 5ï¸âƒ£ Lancer le producer (machine hÃ´te)

âš ï¸ Kafka expose le port 29092 pour les clients externes.
```bash
export KAFKA_BOOTSTRAP=localhost:29092
python producer/produce_logs.py
```

Tu dois voir :
```matlab
Producing to logs_raw @ XXX events/sec
```

### 6ï¸âƒ£ VÃ©rifier la consommation Kafka (Docker)
```bash 
docker exec -it kafka kafka-console-consumer \
--bootstrap-server kafka:9092 \
--topic logs_raw \
--from-beginning
```

### 7ï¸âƒ£ Lancer Spark Streaming

Compiler le projet Scala (si nÃ©cessaire) :

```bash
cd spark-streaming
sbt clean package
```


Soumettre le job :

```bash
docker exec -it spark bash -lc "
/opt/spark/bin/spark-submit \
--master local[*] \
--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 \
--class com.myapp.logs.StreamingJob \
/app/spark-streaming/target/scala-2.12/*.jar
"
```

### 8ï¸âƒ£ VÃ©rifier les donnÃ©es dans HDFS
```bash
docker exec -it namenode hdfs dfs -ls /datalake/logs
docker exec -it namenode hdfs dfs -ls /datalake/logs/curated
```

## ğŸ“Š Traitement Batch et visualisation
### 9ï¸âƒ£ Lancer BatchAnalytics
```bash
cd spark-batch
sbt clean package
```
```bash
docker exec -it spark bash -lc "
/opt/spark/bin/spark-submit \
--master local[*] \
--class com.myapp.logs.BatchAnalytics \
/app/spark-batch/target/scala-2.12/*.jar
"
```

### ğŸ”Ÿ VÃ©rifier les rÃ©sultats analytiques
```bash
docker exec -it namenode hdfs dfs -ls /datalake/logs/analytics
```

Tu dois voir :
- `top_paths`
- `kpi_by_hour`
- `kpi_by_host`
- `top_paths_csv`

### ğŸ” Visualiser les rÃ©sultats (Spark Shell)
```bash
docker exec -it spark /opt/spark/bin/spark-shell
```

Dans le prompt Scala :

```scala
val df = spark.read.parquet("hdfs://namenode:8020/datalake/logs/analytics/top_paths")
df.show(20, false)
df.printSchema()
```
## ğŸ§ª RÃ©sultats produits

- Logs traitÃ©s en temps rÃ©el
- DonnÃ©es stockÃ©es en Parquet
- KPI globaux :
  - Top endpoints
  - Trafic par heure
  - Erreurs serveur
  - Temps de rÃ©ponse moyen

## ğŸ”§ AmÃ©liorations possibles

- Ajout dâ€™une couche de visualisation (Grafana, Superset)
- IntÃ©gration de Delta Lake / Iceberg
- DÃ©ploiement cloud (AWS, Azure, GCP)
- Monitoring avec Prometheus & Grafana

## ğŸ‘¤ Auteur

### **Abdelilah BENCHINE**
Ã‰tudiant en GÃ©nie Informatique â€“ ENSA Tanger <br/>
Projet rÃ©alisÃ© dans le cadre du module **Big Data**

## â­ Remarque finale

Ce projet a Ã©tÃ© conÃ§u Ã  des fins pÃ©dagogiques afin de dÃ©montrer une architecture Big Data complÃ¨te et rÃ©aliste. <br/>
Toute contribution ou amÃ©lioration est la bienvenue.